{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Processing in Python .ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hussain0048/Machine-Learning/blob/master/Data_Processing_in_Python_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX1XA2lOe_hC"
      },
      "source": [
        "# **Table Content**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRvGGuOwfGui"
      },
      "source": [
        "\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "    <ol>\n",
        "        <li><a href=\"https:\">Introduction</a></li>\n",
        "        <li><a href=\"#downloading_data\">Data Loading</a></li>\n",
        "        <li><a href=\"#pre-processing\">Dropping feature</a></li>\n",
        "         <li><a href=\"#pre-processing\">Convert target variable into binary Form</a></li>\n",
        "        <li><a href=\"#setting_up_tree\">Data Imbalanced problem </a></li>\n",
        "        <li><a href=\"#modeling\">Missing Values</a></li>\n",
        "         <li><a href=\"#modeling\">Inconsistent data/Irrelevant features</a></li>\n",
        "        <li><a href=\"#prediction\">Hot Encoding</a></li>\n",
        "        <li><a href=\"#evaluation\">Outlier Detection</a></li>\n",
        "    </ol>\n",
        "</div>\n",
        "<br>\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1xpAC0Sf0EQ"
      },
      "source": [
        "# **1- Introduction** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2tTizNTf7o3"
      },
      "source": [
        "Data preprocessing is an integral step in Machine Learning as the quality of data and the useful information that can be derived from it directly affects the ability of our model to learn; therefore, it is extremely important that we preprocess our data before feeding it into our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2WuuWtcgNG4"
      },
      "source": [
        "# **2- Data Loading**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Biql2sZngvIB"
      },
      "source": [
        "## **2.1 Data Loading from Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwp1rpowgTKQ",
        "outputId": "6502460c-55fc-4ff4-e3b4-9ba466c4241b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RoIsrRghTBm"
      },
      "source": [
        "import pandas as pd \n",
        "Train_data = pd.read_csv('/content/drive/MyDrive/Datasets/Water Brone diesease/Malyria_2-21-2021.csv',encoding = 'latin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hwlf9uUhdzP"
      },
      "source": [
        "Train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbnAH9rKhntf"
      },
      "source": [
        "# **3- Dropping feature**\n",
        "\n",
        "Dropping feature usually isn’t recommended because you’re losing information. But if you’re sure that the column isn’t important, or simply has too many missing values, you can choose to drop them. For example, for this dataset, the host_name column was removed for ethical reasons, and id was removed because it was was unnecessary.\n",
        "To drop features, use drop and set axis to 1 and inplace to true. Axis is 1 because we want to drop columns (0 means row), and inplace is True because you're transforming it directly on your dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfufIU6Ph4DJ"
      },
      "source": [
        "## **3.1 Drop Index Columns**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRMwPJugh_cV"
      },
      "source": [
        "Train_data=Train_data.reset_index()\n",
        "Train_data=Train_data.drop(columns=['index'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ywNezHyiN1J"
      },
      "source": [
        "## **3.2 Drop Multiple featurs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iDC_p4nigy-"
      },
      "source": [
        "New5=Train_data.drop(Train_data.columns[[0,1,3,4,5,6,7,10,17]], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJUyNsNCygat"
      },
      "source": [
        "# Drop unnecessary columns that are not important\n",
        "colsToDrop = ['id','host_name','last_review']\n",
        "\n",
        "airbnb.drop(colsToDrop, axis=1, inplace=True)\n",
        "\n",
        "missing_cols(airbnb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qsjo7VQeynsV"
      },
      "source": [
        "## **3.3-Dropping the row**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYvBStP2yx5f"
      },
      "source": [
        "If you want to remove rows, you do so using dropna . I’m not going to do that because there are no missing values in price."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fb5a_4iyw4b"
      },
      "source": [
        "# remove rows with missing values in price\n",
        "airbnb['price'].dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjrtdkJdkvGz"
      },
      "source": [
        "# **4-Convert target variable into binary Form**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPeuZ7VPk50C"
      },
      "source": [
        "Train_data['RESULT_TEXT'].replace({'Negative': 0, 'Positive': 1},inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgG-pUdEI3CK"
      },
      "source": [
        "# **5- Data Imbalanced problem** [8]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AENif9HTYX7P"
      },
      "source": [
        "Classification is one of the most common machine learning problems. One of the common issues found in datasets that are used for classification is imbalanced classes issue. Generally, we expect the labels to be relatively even distributed. In reality, the samples we can get maybe unsatisfactory.\n",
        "\n",
        "Take a binary classification problem for example, we might encounter too few positive samples in the training dataset, called minority class. And most machine learning techniques will ignore, and in turn have poor performance on, the minority class, although typically it is performance on the minority class that is most important. Such an imbalanced dataset can be addressed by sampling techniques. There are mainly three types of sampling techniques: **Oversampling**, **Undersampling** and **Synthetic Sampling**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKIZZsiLYuLh"
      },
      "source": [
        "**Why Imbalanced dataset is bad?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhwsurmIY_aD"
      },
      "source": [
        "So why does imbalance lead to poor model performance? Because any algorithm cannot obtain enough information from a class with a small sample size to make accurate predictions. The uneven distribution of the corresponding variables reduces the accuracy of the algorithm, and the prediction accuracy for small classes will be very low. The algorithm itself is error-driven, that is, the goal of the model is to minimize the overall error, and the contribution of small classes to the overall error is very low. The algorithms themselves assume that the class distribution of the data set is balanced, and they may also assume that different classes of errors bring the same loss.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU4NCsm0ZwKP"
      },
      "source": [
        "**Oversampling**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQNqBvsQZy1P"
      },
      "source": [
        "This method mainly deals with small classes. Use repeated observations to balance the data. There will not be any information loss using this method, but the addition of small-type repeated samples will easily lead to over-fitting, and the calculation time and storage overhead will also increase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1GSVonCaZ23"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1Zze6DH82-UqfgfYK8J4gerDY18LbH7rO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXyI3y-zahWO"
      },
      "source": [
        "**Undersampling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l07UlmTMapWX"
      },
      "source": [
        "This method is mainly to deal with large categories. Use to reduce the number of observations in large categories to balance the data set. It is suitable when the overall data set is large, and this method can also reduce the calculation time and storage overhead (the training set samples are less). It is also possible to combine the two methods of oversampling and undersampling. The large class uses undersampling without replacement, and the small class uses oversampling with replacement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODqF6fKbbSDe"
      },
      "source": [
        "![](\n",
        "https://drive.google.com/uc?export=view&id=10OLxqUKqVGd_Uknw-Griz4Ultd9sjMYM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTBMrno6lFox"
      },
      "source": [
        "**Synthetic Sampling**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf7crddvlIaY"
      },
      "source": [
        "The synthetic data sampling method uses artificial data instead of repeating the original observations to solve the imbalance. Among those algorithms, ASMOTE (Synthetic Minority Oversampling Technique) is the most common a data sampling technique.\n",
        "SMOTE works by selecting examples that are close in the feature space, drawing a line between the examples in the feature space and drawing a new sample at a point along that line.\n",
        "Specifically, a random example from the minority class is first chosen. Then k of the nearest neighbors for that example are found (typically k=5). A randomly selected neighbor is chosen and a synthetic example is created at a randomly selected point between the two examples in feature space.\n",
        "This procedure can be used to create as many synthetic examples for the minority class as are required. As described in the paper, it suggests first using random undersampling to trim the number of examples in the majority class, then use SMOTE to oversample the minority class to balance the class distribution.\n",
        "The approach is effective because new synthetic examples from the minority class are created that are plausible, that is, are relatively close in feature space to existing examples from the minority class.\n",
        "A general downside of the approach is that synthetic examples are created without considering the majority class, possibly resulting in ambiguous examples if there is a strong overlap for the classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWLw27HglTGH"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1TwyAC1SK2t7fXcdsin6aNGNq0pT48kke)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnxhM4IHjs2s"
      },
      "source": [
        "## **5.1 Check Imbalanced Problem in Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p7TRBevkGlk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "32d5c177-85d7-4ee9-8e7f-191ae22723f3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize = (8,5))\n",
        "Train_data.RESULT_TEXT.value_counts(normalize = True).plot(kind='bar', color= ['skyblue','navy'], alpha = 0.9, rot=0)\n",
        "plt.title('Results Status Negative(0) and Positive(1) in the Imbalanced Dataset')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0qwuF7Dkaw2"
      },
      "source": [
        "## **Data resample**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAnm9UBIkiC1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "a4dd557f-a133-4a32-f985-fbf09b6e9336"
      },
      "source": [
        "from sklearn.utils import resample\n",
        "no = Train_data[Train_data.RESULT_TEXT == 0]\n",
        "yes = Train_data[Train_data.RESULT_TEXT == 1]\n",
        "yes_oversampled = resample(yes, replace=True, n_samples=len(no), random_state=123)\n",
        "oversampled = pd.concat([no, yes_oversampled])\n",
        "fig = plt.figure(figsize = (8,5))\n",
        "oversampled.RESULT_TEXT.value_counts(normalize = True).plot(kind='bar', color= ['skyblue','navy'], alpha = 0.9, rot=0)\n",
        "plt.title('Waterbrone Disease status Nagative(0) and Postive(1) after Oversampling (Balanced Dataset)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7ab433b176bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mno\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRESULT_TEXT\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0myes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRESULT_TEXT\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0myes_oversampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moversampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myes_oversampled\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Train_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vj6qu54toUvU"
      },
      "source": [
        "## **SMOTE** [3,4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vx7USJRr-an"
      },
      "source": [
        "**SMOTE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyZZoekMsBi-"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state=42)\n",
        "X_res, y_res = sm.fit_resample(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uaPffyysR3b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize = (8,5))\n",
        "Train_data.RESULT_TEXT.value_counts(normalize = True).plot(kind='bar', color= ['skyblue','navy'], alpha = 0.9, rot=0)\n",
        "plt.title('Results Status Negative(0) and Positive(1) in the Imbalanced Dataset')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV6XZYU7r4kq"
      },
      "source": [
        "**Borderline-SMOTE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhFU41hbonjg"
      },
      "source": [
        "To change the number of values in class 1, there are two possible methods: **random undersampling **(reduces the number of entries from the majority class) and **synthetic oversampling** (synthetically generating new entries for the minority class).\n",
        "\n",
        "Because we want to provide our model with as much data as possible, we will use a technique called **Borderline-SMOTE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zNnsxEUpPIG"
      },
      "source": [
        "**Borderline-SMOTE**(Borderline Synthetic Minority Oversampling Technique). The reason that Borderline-SMOTE was used as opposed to SMOTE is that it takes synthetically generates data in between different elements in the minority class, while ignoring outliers. Outliers can be defined as features which neighbour more majority points, than minority ones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkUhazdgpcnd"
      },
      "source": [
        "Below is the code to apply Borderline-SMOTE. It is important to only balance the training data, as the test series must reflect real-world field data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gze3AZIAq4S6"
      },
      "source": [
        "from imblearn.over_sampling import BorderlineSMOTE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfTtoEcLqMpq"
      },
      "source": [
        "X_train_Before= X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqfQKTG3qRtw"
      },
      "source": [
        "y_train_Before= y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnYGDx8KpeTN"
      },
      "source": [
        "borderlineSMOTE = BorderlineSMOTE(k_neighbors = 10, random_state = 42)\n",
        "X_train, y_train = borderlineSMOTE.fit_resample(X_train_Before,y_train_Before)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmcHEc1llpEt"
      },
      "source": [
        "#**6- Missing Values** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBtctHfzJGya"
      },
      "source": [
        "## **6.1 Why do We Need to Fill Missing Values in a Dataset?**\n",
        "\n",
        "Sometimes the dataset we use to solve a problem contains a lot of missing values that can adversely affect the performance of a machine learning model. A dataset with a lot of missing values can give us wrong information. So if we have missing values in a dataset, here are some strategies we can choose to deal with them:\n",
        "\n",
        "- Removing the whole row which contains missing values\n",
        "- Filling the missing values according to the other known values\n",
        "\n",
        "The first strategy is to remove the entire row containing a missing value. This is not a bad idea, but it can only be considered when the data is very large. If removing missing values results in a data shortage, then this will not be an ideal dataset for any data science task. This is where the second strategy comes in, which is to fill in the missing values according to the other known values. This strategy can be considered in any type of dataset.\n",
        "\n",
        "So this is why we need to fill the missing values in a dataset. In the section below, I will take you through a tutorial on how to fill in missing values in a dataset using Python.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z000rrTwmym1"
      },
      "source": [
        "## **6.2- Check missing Value**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "Jkrr2G-rm8Hj",
        "outputId": "3032a75c-9eec-42a5-d4dd-910160798785"
      },
      "source": [
        "total = oversampled.isnull().sum().sort_values(ascending=False)\n",
        "percent = (oversampled.isnull().sum()/oversampled.isnull().count()).sort_values(ascending=False)\n",
        "missing = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "missing.head(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>Percent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>REPORT_VERIFIED</th>\n",
              "      <td>796</td>\n",
              "      <td>0.01749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RESULT_TEXT</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CPT_ID.1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RESULT_VALUE</th>\n",
              "      <td>0</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Total  Percent\n",
              "REPORT_VERIFIED    796  0.01749\n",
              "RESULT_TEXT          0  0.00000\n",
              "CPT_ID.1             0  0.00000\n",
              "RESULT_VALUE         0  0.00000"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZP1cNqkoE6r"
      },
      "source": [
        "If you want to see missing values for all columns, use this command:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nrfoBBHoD8x"
      },
      "source": [
        "oversampled.isnull().sum()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk74p_4CoUpy"
      },
      "source": [
        "This gives you the percentage of missing values in each of the columns. Knowing the percentage can be useful in determining whether you should drop the column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JPUXvgboWmO"
      },
      "source": [
        "def perc_missing(df):\n",
        "    '''prints out columns with missing values with its %'''\n",
        "    for col in df.columns:\n",
        "        pct = df[col].isna().mean() * 100\n",
        "        if (pct != 0):\n",
        "            print('{} => {}%'.format(col, round(pct, 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjQAQBkJocsC",
        "outputId": "82ed9288-2e86-4b1a-80d3-77cd3bc57bc2"
      },
      "source": [
        "perc_missing(oversampled)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REPORT_VERIFIED => 1.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYV__mY_ot7z"
      },
      "source": [
        "**Heatmap of missing values**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbSrUwtmowVM"
      },
      "source": [
        "Heatmaps are also useful to visualize your missing values, in particular at which point of the data do missing values exists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ1zvi_BpGLq"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BibF54QEo0xB"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(oversampled.isnull(), yticklabels=False, cmap='viridis', cbar=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bjlno6_vJrWT"
      },
      "source": [
        "## **6.3 Fill Missing Values in a Dataset using Python**\n",
        "\n",
        "The scikit-learn library in Python offers the **SimpleImputer()** class which can be used for filling the missing values based on:\n",
        "\n",
        "- Mean of the known values\n",
        "- Median of the known values\n",
        "- Most frequent value among the known values\n",
        "\n",
        "So let’s go through all these methods one by one for filling the missing values of a dataset. I will first create a very simple dataset with some missing values:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwAapSDzIlmZ"
      },
      "source": [
        "import numpy as np\n",
        "data = np.array([[10, np.nan, 8], \n",
        "                 [9, 8, np.nan], \n",
        "                 [7, 10, 9]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T0jy1jtKHir",
        "outputId": "90f4a826-9345-45ce-97fc-3658bbccff65"
      },
      "source": [
        "print(data)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10. nan  8.]\n",
            " [ 9.  8. nan]\n",
            " [ 7. 10.  9.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfYMTMvOKNAi"
      },
      "source": [
        "Here is how you can use the Mean of the other known values for filling the missing values:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAPCWk9XKOli"
      },
      "source": [
        "# Filling Values with mean\n",
        "from sklearn.impute import SimpleImputer\n",
        "mean_values = SimpleImputer(strategy='mean')\n",
        "data1 = mean_values.fit_transform(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAxbT6vXKWUL",
        "outputId": "a9265655-03ec-4332-b2fe-8a50ec5c934e"
      },
      "source": [
        "print(data1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10.   9.   8. ]\n",
            " [ 9.   8.   8.5]\n",
            " [ 7.  10.   9. ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzSA3l3YKaCa"
      },
      "source": [
        "Here is how you can use the Median of the other known values for filling the missing values:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJY6oLTkKfKZ",
        "outputId": "c7320cb8-74f6-4421-e414-98efabd8b0ca"
      },
      "source": [
        "# Filling Values with median\n",
        "from sklearn.impute import SimpleImputer\n",
        "median_values = SimpleImputer(strategy='median')\n",
        "data2 = median_values.fit_transform(data)\n",
        "print(data2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10.   9.   8. ]\n",
            " [ 9.   8.   8.5]\n",
            " [ 7.  10.   9. ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHelgUGeKnfi"
      },
      "source": [
        "Here is how you can use the most frequent value among the other known values for filling the missing values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE900achKj6a",
        "outputId": "128d4f81-ad64-4213-f67d-d40468dfa7af"
      },
      "source": [
        "# Filling values with most frequent values\n",
        "from sklearn.impute import SimpleImputer\n",
        "most_frequent = SimpleImputer(strategy='most_frequent')\n",
        "data3 = most_frequent.fit_transform(data)\n",
        "print(data3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10.  8.  8.]\n",
            " [ 9.  8.  8.]\n",
            " [ 7. 10.  9.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCTUDxFjzd3g"
      },
      "source": [
        "**Imputing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHy-lrI8zipr"
      },
      "source": [
        "For imputing, there are 3 main techniques shown below.\n",
        "\n",
        "- fillna — filling in null values based on given value (mean, median, mode, or specified value)\n",
        "- bfill / ffill — stands for backward fill and forward fill (filling in missing values based on the value after or before the column.)\n",
        "- Simple Imputer — Sk-learn’s built-in function that imputes missing values (commonly used alongside a pipeline when building ML models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzkrPxWtzwlr"
      },
      "source": [
        "Below you can find examples of applying these methods to the price column if it had missing values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQln8P7xzyN1"
      },
      "source": [
        "# imputing price with mean\n",
        "price_mean_value = round(airbnb['price'].mean(), 2)\n",
        "airbnb['price'].fillna(price_mean_value, inplace=True)\n",
        "\n",
        "# imputing price with median\n",
        "price_median_value = round(airbnb['price'].median(), 2)\n",
        "airbnb['price'].fillna(price_median_value, inplace=True)\n",
        "\n",
        "# imputing with bfill or ffill\n",
        "airbnb['price'].bfill(inplace=True)\n",
        "airbnb['price'].ffill(inplace=True)\n",
        "\n",
        "# imputing with SimpleImputor from the sklearn library\n",
        "from sklearn.impute import SimpleImputer\n",
        "# define the imputer\n",
        "imr = SimpleImputer(missing_values=np.nan, strategy='mean') # or median\n",
        "\n",
        "airbnb[['price']] = imr.fit_transform(airbnb[['price']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDx8A9_Uz5jG"
      },
      "source": [
        "**Replace**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wyjcdju7z8CP"
      },
      "source": [
        "To replace values, the fillna function is also used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkqWOIfmz__l"
      },
      "source": [
        "You define the value you want to replace in the key, and the substitute in the value — {column_name: replacement_for_NA}\n",
        "\n",
        "Here are examples for replacing values in the columns reviews_per_month and name\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJIzbrvo0IgT"
      },
      "source": [
        "# replace null values in reviews_per_month with 0 \n",
        "airbnb.fillna({'reviews_per_month':0}, inplace=True)\n",
        "\n",
        "missing_cols(airbnb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2256NAA0P0b"
      },
      "source": [
        "# replace null values in name with 'None'\n",
        "airbnb.fillna({'name':'None'}, inplace=True)\n",
        "\n",
        "missing_cols(airbnb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFbHCw8y0gp0"
      },
      "source": [
        "# **7-Inconsistent data/Irrelevant features**\n",
        "\n",
        "Inconsistent data refers to things like spelling errors in your data, column names that are not relevant to the data, the wrong data type, etc.\n",
        "Here are a couple examples for dealing with these issues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slY5-kmu008V"
      },
      "source": [
        "**Remove rows based on regex**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTjb9zNg03PD"
      },
      "source": [
        "Let’s say you want to remove rows that contain a certain word. For my example, I chose the word noisy/Noisy as my target, and I used the function str.contains() to find the indexes that contain those rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh01cN2Q1hHe"
      },
      "source": [
        "Then, using the drop function, and setting axis to index, I can supply the indexes I have and drop those rows.\n",
        "Printing out the number of rows, you can see it reduced by three."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPUdWVLA1n9l"
      },
      "source": [
        "# example: remove rows that contain the target word\n",
        "target = '[Nn]oisy'\n",
        "\n",
        "noisy_airbnb = airbnb[airbnb['name'].str.contains(target, regex=True)]\n",
        "\n",
        "# show rows that contains the word noisy\n",
        "print(noisy_airbnb['name'])\n",
        "\n",
        "# get the index that contains the word noisy\n",
        "index_to_drop = noisy_airbnb['name'].index\n",
        "\n",
        "# print(index_to_drop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaSmQkCq1tDk"
      },
      "source": [
        "# drop rows based on index\n",
        "airbnb.drop(index_to_drop, axis='index', inplace=True)\n",
        "\n",
        "print(len(airbnb_ori))\n",
        "print(len(airbnb))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgJXAq3H15Y6"
      },
      "source": [
        "**Spelling errors in categorical data**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4HwFy_K18iq"
      },
      "source": [
        "Sometimes your categorical data might have spelling errors or different capitalization that can mess up your categorization.\n",
        "\n",
        "I will be using the neighbourhood_group column as an example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuOFkxYd2BrV"
      },
      "source": [
        "airbnb['neighbourhood_group'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SksmVjW2cCK"
      },
      "source": [
        "You can see the different types of neighborhoods are already well categorized. But what if it wasn’t?\n",
        "\n",
        "To simulate a scenario where some of the data had capitalization or spelling issues, I sampled 2 rows from the data, and replaced them with the wrong spelling.\n",
        "\n",
        "You can see now how the categorization is messed up. “Manhattan” and “manhatann” refer to the same thing, but they aren’t in the same category because of capitalization. Same goes for “brookln” due to spelling issues.\n",
        "\n",
        "We can fix this by using the replace function in pandas. We first give the values that are wrong, then supply the right ones. Notice the values have to match each other in the list, i.e. “manhatann” → “Manhattan”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGHMa3Kf2nwr"
      },
      "source": [
        "random_index = airbnb.sample(2, random_state = 10).index\n",
        "\n",
        "# airbnb['neighbourhood_group'].loc[random_index]\n",
        "## we randomly selected Manhattan and Brooklyn\n",
        "\n",
        "wrong_spelling = ['manhatann', 'brookln']\n",
        "\n",
        "# replace them with the wrong spelling\n",
        "airbnb.loc[random_index,'neighbourhood_group'] = wrong_spelling\n",
        "airbnb['neighbourhood_group'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "615qZufj2t4y"
      },
      "source": [
        "airbnb['neighbourhood_group'].replace(['manhatann', 'brookln'],\n",
        "                             ['Manhattan', 'Brooklyn'], inplace=True)\n",
        "airbnb['neighbourhood_group'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1vCjhl4211-"
      },
      "source": [
        "**Renaming columns**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92NhJPml236k"
      },
      "source": [
        "There are cases where you want to rename your columns as well.\n",
        "\n",
        "You can do this by using a dictionary, setting the key as the original column name, and the value as the new column name.\n",
        "\n",
        "Then using the rename function we give our dictionary and voila, the columns names have changed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCbivQOE3DEM"
      },
      "source": [
        "new_names = {'name':'listing_name', 'latitude':'lat', 'longitude':'long'}\n",
        "\n",
        "airbnb.rename(columns=new_names, inplace=True)\n",
        "airbnb.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg8UEqbN8aSv"
      },
      "source": [
        "The dataset that I am using here does not have columns names, so let’s give the most appropriate names to these columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9g4R2ZE8f-h"
      },
      "source": [
        "data.columns = ['user_id', 'product_id','ratings','timestamp']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XY4SMhhE3JzD"
      },
      "source": [
        "**Converting to DateTime**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38V5TvtC3Rh7"
      },
      "source": [
        "If you have data that should be a datetime object, but are strings, you can use the pd.to_datetime, and pass it the format that represents your data.\n",
        "\n",
        "Just like that, the column has converted into a datatime data type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo5kySe53VzP"
      },
      "source": [
        "airbnb_ori['last_review'] = pd.to_datetime(airbnb_ori['last_review'], format='%Y-%m-%d')\n",
        "airbnb_ori['last_review'].dtype.type"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2WhiJKU3dvq"
      },
      "source": [
        "**Duplicates**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaJJWjI_3g3w"
      },
      "source": [
        "There are cases where your rows have duplicate values, this could’ve happened due to some mishaps in your data collection.\n",
        "\n",
        "To find out if you have duplicated values, call duplicated().any() on your data frame, and if it’s true, use the drop_duplicates function\n",
        "\n",
        "You can also specify columns where you want to remove duplicate values like below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A61D9z53pKj"
      },
      "source": [
        "airbnb.duplicated().any()\n",
        "\n",
        "## if true\n",
        "# airbnb.drop_duplicates()\n",
        "\n",
        "## if you want to drop duplicates at specific column\n",
        "# airbnb.drop('col_name', axis=1, inplace=True).drop_duplicates()\n",
        "False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxGRgpQN3tTC"
      },
      "source": [
        "**Change data type to reduce memory**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2EFB99C3wKj"
      },
      "source": [
        "Changing data type is common if you want to reduce memory usage.\n",
        "\n",
        "To do so, you can use the astype(‘dtype’) function where you specify the dtype you want.\n",
        "\n",
        "In my example, I changed the data type for the host_id column from int64 to int32\n",
        "\n",
        "Observe the memory before changing the data type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fafd0hgO38vE"
      },
      "source": [
        "airbnb.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFv7767y4Hru"
      },
      "source": [
        "airbnb['host_id'] = airbnb['host_id'].astype('int32')\n",
        "airbnb.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p46jyLsb4MZZ"
      },
      "source": [
        "You can see the memory reduced from 6.5+ to 6.3+ MB."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orpFOyirp-Cd"
      },
      "source": [
        "# **8-Encoding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4QgkyTXmeIS"
      },
      "source": [
        "**Machine Learning type of Data**[9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_JZmyZDm2Xp"
      },
      "source": [
        "Data Science is the art and science of solving real-world problems and making data-driven decisions. It primarily deals with all kinds of structured or unstructured data. Data, broadly, can be divided into two types i.e., Numerical and Categorical. Most of the data science models are equipped to work with **numerical data**; however, things get interesting when we have to deal with **Categorical data**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dypN39IInD3w"
      },
      "source": [
        "**What is Categorical data?**[9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfrBwUDJnN9n"
      },
      "source": [
        "Categorical data is a form of data that takes on values within a finite set of discrete classes. It is difficult to count or measure categorical data using numbers and therefore they are divided into categories. An example of categorical data would be Gender of a person. It can only take values between Male, Female, and Others.\n",
        "There are two types of categorical variables:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi5xyxuYoMDe"
      },
      "source": [
        "**I. Ordinal Variables:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8vi5AOgoOsm"
      },
      "source": [
        "These variables maintain a natural order in their class of values. If we consider the level of education then we can easily sort them according to their education tag in the order of High School < Under-Graduate<post-Graduate < PhD. The review rating system can also be considered as an ordinal data type where 5 stars is definitely better than 1 star."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjoCmUsyoZcE"
      },
      "source": [
        "I**I. Nominal Variables:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBjqZNclooA5"
      },
      "source": [
        "These variables do not maintain any natural/logical order. The color of a car can be considered as Nominal Variable as we cannot compare the color with each other. It is impossible to state that “Red” is better than “Blue” (subjective!). Similarly, Gender is a type of Nominal Variable as again we cannot differentiate between Male, Female, and Others."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGATCWIXou4Z"
      },
      "source": [
        "**Encoding Categorical Data:**[9]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5KT7XjYo4KI"
      },
      "source": [
        "Most of the Machine learning algorithms are designed to work with numeric data. Hence, we need to convert Categorical(text) data into numerical data for model building. There are multiple encoding techniques to convert categorical data into numerical data. Let’s look at some of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1gF3x2VX8wL"
      },
      "source": [
        "When working on some datasets, we found that some of the features are categorical, if we pass that feature directly to our model, our model can't understand those feature variables. We all know that machines can't understand categorical data. Machines require all independent and dependent variables i.e input and output features to be numeric. This means that if our data contain a categorical variable, we must have to encode it to the numbers before we fit our data to the model.\n",
        "\n",
        "Models only work with numerical values. For this reason, it is necessary to convert the categorical values of the features into numerical ones, So the machine can learn from those data and gives the right model. This process of converting categorical data into numerical data is called **Encoding** [6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFb6GAEApROW"
      },
      "source": [
        "There are multiple ways of encoding techniques to deal with these variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDOjfOBEYf5N"
      },
      "source": [
        "The two most popular techniques of encoding are,\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1rZA8G2YiYF"
      },
      "source": [
        "## **Nominal Encoding [7]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQuw6Na-ZCU_"
      },
      "source": [
        "When we have a feature where variables are just names and there is no order or rank to this variable's feature.For example: City of person lives in, Gender of person, Marital Status, etc…\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab2VkiHFZbCd"
      },
      "source": [
        "In the above example, We do not have any order or rank, or sequence. All the variables in the respective feature are equal. We can't give them any orders or ranks. Those features are called Nominal features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0yExvnid2uo"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1EzEpCh6IEsZ0RKlDb_8c0fX376-M61ny)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeCGPIcVeAHS"
      },
      "source": [
        "## **Ordinal Encoding [7]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY5SNrg8pb1l"
      },
      "source": [
        "Ordinal Encoding primarily encodes ordinal categories into ordered numerical values. Ordinal encoding maps each unique category value to a specific numerical value based on its order or rank. Consider the education column in the given data frame. Here, we define the ordering of the categories when creating an ordinal encoder using sklearn. so, in the example, we arrange the order inside the categories as a list in ascending order. First, we have the High School followed by Associate,Master, and then Ph.D. at the end.[9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPtUBoxTv-Pf"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPJHjLF3eOQo"
      },
      "source": [
        "When we have a feature where variables have some order/rank.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XtvDIhvedAe"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1G1oAtnnuIuAApxdPPU80679T8rtDpntH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYq-hnQAeSgK"
      },
      "source": [
        "For example: Student’s performance, Customer’s review, Education of person, etc…"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLROx2pJebAG"
      },
      "source": [
        "In the above example, we have orders/ranks/sequences. We can assign ranks based on student's performance, based on feedback given by customers, based on the highest education of the person. Those features are called Ordinal features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPoe8uD4p2Qr"
      },
      "source": [
        "[OrdinalEncoder(categories=[[‘HS’, ‘AS’, ‘M.S’, ‘Ph.D.’]])]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxdov92MqB4Z"
      },
      "source": [
        "df['Education'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEdStYMbqL-5"
      },
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "ordinal = OrdinalEncoder(categories=[['HS', 'AS', 'M.S','Ph.D']])\n",
        "df['Education'] = ordinal.fit_transform(df[['Education']])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYrfQTE5qQsq"
      },
      "source": [
        "![](\n",
        "https://drive.google.com/uc?export=view&id=1jnxgK8GKTX1HyWXyOLDgqmYQqns98njI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8boEcj6q8v5"
      },
      "source": [
        "The ordinal encoder is the most suitable option for encoding ordinal variables. It helps the machine learning model to establish a relationship between a categorical column and the target column. For example, if we want to predict the salary of an employee, it would depend on different features, and education level would be one of those features. Now, logically the one with Ph.D. will have a better salary than the one with a high school degree. so, the model will learn that a Ph.D. with a value of 3 in the data frame weighs more than the one with a high school degree with a value of 0. This way the model will learn that when the level of education goes up, the salary increases and vice versa.[9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIoU6rrjrLaY"
      },
      "source": [
        "## **One Hot Encoding**:[9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOtCZyEwwA52"
      },
      "source": [
        "If there is no ordinal relationship between the categorical variables then ordinal encoding might mislead the model. This is because the ordinal encoder will try to force an ordinal relationship on the variables to assume a natural ordering, thus resulting in poor performance.\n",
        "In this case, One Hot encoder should be used to treat our categorical variables. It will create dummy variables by converting N categories into N features/columns. Considering the gender column again. If we have a male in the first row, then its value is 1. Also if we have a female in the second row then its value is 0. Whenever the category exists its value is 1 and 0 where it does not. We can one-hot encode categorical variables in two ways. One, by using get_dummies in pandas and two, by using OneHotEncoder from sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaZV_eZjwHUG"
      },
      "source": [
        "pd.get_dummies(df['Gender']).head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "452Af_mKwIf1"
      },
      "source": [
        "![](\n",
        "https://drive.google.com/uc?export=view&id=1HuX3C28bC8pwODt9xiPXWzTxsN5ICxhJ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5r7cKZrvwxwS"
      },
      "source": [
        "Another example is Marital Status. Here, we have three different categories Married: M, Divorced: D, and Single: S. we can reduce the dimensionality by one column by using: “drop_first=True” meaning the number of columns will be one less than the number of categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pNsHRALw16i"
      },
      "source": [
        "pd.get_dummies(df['Marital Status'],drop_first=True).head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD9NJVmWxXk6"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1kbocIUE7gHMIcbnZtC7CluQMUqdty5G4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MUXlTIzxgjo"
      },
      "source": [
        "In the second row of the table above, we have zero for married and single, which effectively means that it is Divorced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_b_Qho_xiT5"
      },
      "source": [
        "If we assign drop_first =False, then we still have three columns: Married, Single, and Divorced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMhpy3o5xmWB"
      },
      "source": [
        "pd.get_dummies(df['Marital Status'],drop_first=False).head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utFZYVsfyFYS"
      },
      "source": [
        "![](https://drive.google.com/uc?export=view&id=1j654yAZy1pZiMX7uyjmzXXPWlnkag-Vz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8LqoGmZyPuP"
      },
      "source": [
        "As mentioned, we can also implement one-hot encoding through OneHotEncoder from sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LlVVEu7ySC3"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder(sparse=False)\n",
        "ohe.fit_transform(df0[['Marital Status']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amsik25XyVyH"
      },
      "source": [
        "If we have a high number of categorical variables in a column, then we should avoid using one-hot encoding. It will result in an increase in the number of corresponding columns which will give rise to a problem called “Curse of Dimensionality”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xarFJmqzqNdt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1af80992-4f75-4adb-9b35-f8898c3850fc"
      },
      "source": [
        "oversampled.select_dtypes(include=['object']).columns\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['MRNO', 'AGE', 'GENDER', 'DISTRICT', 'TEHSIL', 'REPORT_VERIFIED',\n",
              "       'RESULT_VALUE'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkfkPLXEqSSi"
      },
      "source": [
        "# Impute categorical var with Mode\n",
        "oversampled['MRNO'] = oversampled['MRNO'].fillna(oversampled['MRNO'].mode()[0])\n",
        "oversampled['AGE'] = oversampled['AGE'].fillna(oversampled['AGE'].mode()[0])\n",
        "oversampled['GENDER'] = oversampled['GENDER'].fillna(oversampled['GENDER'].mode()[0])\n",
        "oversampled['DISTRICT'] = oversampled['DISTRICT'].fillna(oversampled['DISTRICT'].mode()[0])\n",
        "oversampled['TEHSIL'] = oversampled['TEHSIL'].fillna(oversampled['TEHSIL'].mode()[0])\n",
        "oversampled['REPORT_VERIFIED'] = oversampled['REPORT_VERIFIED'].fillna(oversampled['REPORT_VERIFIED'].mode()[0])\n",
        "oversampled['RESULT_VALUE'] = oversampled['RESULT_VALUE'].fillna(oversampled['RESULT_VALUE'].mode()[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrGan4YLqbCI"
      },
      "source": [
        "# Convert categorical features to continuous features with Label Encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lencoders = {}\n",
        "for col in oversampled.select_dtypes(include=['object']).columns:\n",
        "    lencoders[col] = LabelEncoder()\n",
        "    oversampled[col] = lencoders[col].fit_transform(oversampled[col])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPPO6refqh0o"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# Multiple Imputation by Chained Equations\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "MiceImputed = oversampled.copy(deep=True) \n",
        "mice_imputer = IterativeImputer()\n",
        "MiceImputed.iloc[:, :] = mice_imputer.fit_transform(oversampled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nCdkFRKsGV6"
      },
      "source": [
        "## **Label_Encoding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRl1fZL-_EUB"
      },
      "source": [
        "The label encoder will convert each category into a unique numerical value. If implemented with Sklearn, then this encoder should be used to encode output values, i.e. y, and not the input X. It is similar to the ordinal encoder except, here the numeric values are assigned automatically without following any sort of natural order. Generally, the alphabetical order of the categorical values is used to determine which numerical value comes first. Considering our target variable “Job Status” column has four different categories. After applying label encoding to this column the four different categories are mapped into integers 0: Full Time, 1: Intern, 2: Part-Time, and 3:Unemployed. With this, it can be interpreted that Unemployed have a higher priority than Part-Time, Full Time, and Intern while training the model, whereas, there is no such priority or relation between these statuses. We can’t define the order of labels with the label encoding technique."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRS-UR11_JJw"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder \n",
        "lbe = LabelEncoder()\n",
        "df['Employment Status']= lbe.fit_transform(df['Employment Status']) \n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6Y9_6n8A0MU"
      },
      "source": [
        "\n",
        "[](https://drive.google.com/uc?export=view&id=1j654yAZy1pZiMX7uyjmzXXPWlnkag-Vz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKP9_lp3_RRf"
      },
      "source": [
        "The disadvantage to label encoding is that it gives an order to the categorical value, which might not be suitable to some machine learning algorithms such as Linear Regression, as they are too sensitive to the values; in such case, one hot encoding provides better results.\n",
        "On the other hand, label encoding is suitable with Decision Tree and Random Forest algorithms because they don’t depend on the values of the categorical variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhYgelLK9G8Z"
      },
      "source": [
        "Import Dataset-\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuqmKLVv9NAx"
      },
      "source": [
        "import seaborn as sns\n",
        "df=sns.load_dataset('titanic')\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSXNdKhz9Uwn"
      },
      "source": [
        "So, I am considering categorical features and will try to find out the top important features. Creating a data frame for categorical features. We need to compare all the categories with the output category (Survived)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Hdsfcixq9aSf",
        "outputId": "db8c4af6-1078-4cab-fcbe-6e2af6aa0f64"
      },
      "source": [
        "##['sex','embarked','alone','pclass','Survived']\n",
        "df=df[['sex','embarked','alone','pclass','survived']]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>embarked</th>\n",
              "      <th>alone</th>\n",
              "      <th>pclass</th>\n",
              "      <th>survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>male</td>\n",
              "      <td>S</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>C</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>female</td>\n",
              "      <td>S</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>female</td>\n",
              "      <td>S</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>male</td>\n",
              "      <td>S</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      sex embarked  alone  pclass  survived\n",
              "0    male        S  False       3         0\n",
              "1  female        C  False       1         1\n",
              "2  female        S   True       3         1\n",
              "3  female        S  False       1         1\n",
              "4    male        S   True       3         0"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVtVy1br9gxJ"
      },
      "source": [
        "Let’s perform label encoding on the embarked\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iF7vDNz9mtY"
      },
      "source": [
        "df['sex']=np.where(df['sex']==\"male\",1,0)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJjiGyo29zBz"
      },
      "source": [
        "#Let’s perform label encoding on the embarked\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMFVQ6-B9wUY"
      },
      "source": [
        "import numpy as np\n",
        "### let's perform label encoding on embarked\n",
        "ordinal_label = {k: i for i, k in enumerate(df['embarked'].unique(), 0)}\n",
        "df['embarked'] = df['embarked'].map(ordinal_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Z93qFiJF9-LW",
        "outputId": "82373f89-616f-4c85-ddec-77ab9cb4e55c"
      },
      "source": [
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>embarked</th>\n",
              "      <th>alone</th>\n",
              "      <th>pclass</th>\n",
              "      <th>survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sex  embarked  alone  pclass  survived\n",
              "0    1         0  False       3         0\n",
              "1    0         1  False       1         1\n",
              "2    0         0   True       3         1\n",
              "3    0         0  False       1         1\n",
              "4    1         0   True       3         0"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOXQ48L5-GWW"
      },
      "source": [
        "#Performing label encoding on alone\n",
        "## let's perform label encoding on alone\n",
        "df['alone']=np.where(df['alone']==True,1,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Dj0pu0gh-URc",
        "outputId": "7184381b-9d76-46b0-82e4-ec1350b555f8"
      },
      "source": [
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>embarked</th>\n",
              "      <th>alone</th>\n",
              "      <th>pclass</th>\n",
              "      <th>survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sex  embarked  alone  pclass  survived\n",
              "0    1         0      0       3         0\n",
              "1    0         1      0       1         1\n",
              "2    0         0      1       3         1\n",
              "3    0         0      0       1         1\n",
              "4    1         0      1       3         0"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OoCHQ6TwE_f"
      },
      "source": [
        "# **9-Outlier detection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k2wkbevQ0KQ"
      },
      "source": [
        "**Defination:**Outlier is an observation point that is distant from other observations.Extreme values can be present in both dependent & independent variables, in the case of supervised learning methods.\n",
        "\n",
        "These extreme values need not necessarily impact the model performance or accuracy, but when they do they are called “Influential” points. Many machine learning models, like linear & logistic regression, are easily impacted by the outliers in the training data.Models like AdaBoost increase the weights of misclassified points on every iteration and therefore might put high weights on these outliers as they tend to be often misclassified. This can become an issue if that outlier is an error of some type, or if we want our model to generalize well and not care for extreme values.To overcome this issue, we can either change the model or metric, or we can make some changes in the data and use the same models [5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdlYsfevSLSv"
      },
      "source": [
        "**Extreme Values in Independent Variables [5]**\n",
        "\n",
        "These are called points of “high leverage”. With a single predictor, an extreme value is simply one that is particularly high or low. With multiple predictors, extreme values may be particularly high or low for one or more predictors (univariate analysis — analysis of one variable at a time) or may be “unusual” combinations of predictor values (multivariate analysis)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6u5JcpQSqPR"
      },
      "source": [
        "**Extreme Values in Target Variables [5]**\n",
        "\n",
        "Regression — these extreme values are termed as “outliers”. They may or may not be influential points\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6Fa2YQ2S62A"
      },
      "source": [
        "Classification: Here, we have two types of extreme values:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj0_azsUTQRx"
      },
      "source": [
        "1. **Outliers:** For example, in an image classification problem in which we’re trying to identify dogs/cats, one of the images in the training set has a gorilla (or any other category not part of the goal of the problem) by mistake. Here, the gorilla image is clearly noise. Detecting outliers here does not make sense because we already know which categories we want to focus on and which to discard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-8ezNNKTZJ3"
      },
      "source": [
        "2. **Novelties:** Many times we’re dealing with novelties, and the problem is often called supervised anomaly detection. In this case, the goal is not to remove outliers or reduce their impact, but we are interested in detecting anomalies in new observations. Therefore we won’t be discussing it in this post. It is especially used for fraud detection in credit-card transactions, fake calls, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ModLlb4mTucn"
      },
      "source": [
        "Our major focus will be outliers (extreme values in target variable for further investigation and treatment). We’ll see the impact of these extreme values on the model’s performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htiwFPisfBNg"
      },
      "source": [
        "## **9.1 Common Methods for Detecting Outliers [5]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o137YJKT7TI"
      },
      "source": [
        "**Common Methods for Detecting Outliers [5]**\n",
        "\n",
        "When detecting outliers, we are either doing univariate analysis or multivariate analysis. When your linear model has a single predictor, then you can use univariate analysis. However, it can give misleading results if you use it for multiple predictors. One common way of performing outlier detection is to assume that the regular data come from a known distribution (e.g. data are Gaussian distributed). This assumption is discussed in the Z-Score method section below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr8JhIW3UQ2Y"
      },
      "source": [
        "1. **Box-Plot**\n",
        "\n",
        "The quickest and easiest way to identify outliers is by visualizing them using plots. If your dataset is not huge (approx. up to 10k observations & 100 features), I would highly recommend you build scatter plots & box-plots of variables. If there aren’t outliers, you’ll definitely gain some other insights like correlations, variability, or external factors like the impact of world war/recession on economic factors. However, this method is not recommended for high dimensional data where the power of visualization fails.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSU43eKUUhD2"
      },
      "source": [
        "The box plot uses inter-quartile range to detect outliers.\n",
        "\n",
        " Here, we first determine the quartiles Q1 and Q3.\n",
        "\n",
        "Interquartile range is given by, IQR = Q3 — Q1\n",
        "\n",
        "Upper limit = Q3+1.5*IQR\n",
        "\n",
        "Lower limit = Q1–1.5*IQR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40KHu8jfVU-2"
      },
      "source": [
        "![](\n",
        "https://drive.google.com/uc?export=view&id=1Co72C3c03NmxMSXaLVOKb6HDlr10X6Mf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiSoTDtMVj-s"
      },
      "source": [
        "2. **Cook’s Distance**\n",
        "\n",
        "This is a multivariate approach for finding influential points. These points may or may not be outliers as explained above, but they have the power to influence the regression model. We will see their impact in the later part of the blog.\n",
        "This method is used only for linear regression and therefore has a limited application. Cook’s distance measures the effect of deleting a given observation. It’s represents the sum of all the changes in the regression model when observation “i” is removed from it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFq1ZvGiVr88"
      },
      "source": [
        "3. **Z-Score**\n",
        "\n",
        "This method assumes that the variable has a Gaussian distribution. It represents the number of standard deviations an observation is away from the mean:\n",
        "\n",
        "Here, we normally define outliers as points whose modulus of z-score is greater than a threshold value. This threshold value is usually greater than 2 (3 is a common value).\n",
        "\n",
        "All the above methods are good for initial analysis of data, but they don’t have much value in multivariate settings or with high dimensional data. For such datasets, we have to use advanced methods like PCA, LOF (Local Outlier Factor) & HiCS: High Contrast Subspaces for Density-Based Outlier Ranking.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL0Q2JbrWw5s"
      },
      "source": [
        "![](\n",
        "https://drive.google.com/uc?export=view&id=1E2H2NHulGaphunf9oVV_mVRCbgoS1I3e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7gu5ktGW74j"
      },
      "source": [
        "![](\n",
        "https://drive.google.com/uc?export=view&id=1SQkD3XMh-VTNY2fe-mcDaVepK1IJNaP7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tq6yjKx4jg8"
      },
      "source": [
        "Outliers can be dangerous as they can skew your model and give you predictions that are biased and erroneous.\n",
        "The best way to find outliers is to use the describe function and look at information such as maximum and mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FseYShGQwc1n"
      },
      "source": [
        "# Detecting outliers with IQR\n",
        "Q1 = MiceImputed.quantile(0.25)\n",
        "Q3 = MiceImputed.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "print(IQR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLYT9hGawiaP"
      },
      "source": [
        "# Removing outliers from the dataset\n",
        "MiceImputed = MiceImputed[~((MiceImputed < (Q1 - 1.5 * IQR)) |(MiceImputed > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "MiceImputed.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQL0D8K24wse"
      },
      "source": [
        "You can also plot a histogram and look at the distribution of your data.\n",
        "\n",
        "In this histogram, you can see that most of the data is around 0 to 5000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "c34xlum141Cl",
        "outputId": "176b3f71-eda4-484d-9cc7-d3ed06100b84"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "MiceImputed['RESULT_TEXT'].hist(bins=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f573a604290>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqyFTeET5TZu"
      },
      "source": [
        "A boxplot is also useful in detecting outliers.\n",
        "\n",
        "As you can see, the price column has multiple data points that are outliers (above of the maximum in the boxplot)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MhlqVJ75ZEF"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "MiceImputed.boxplot(column=['RESULT_TEXT'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qx-t0PnF527E"
      },
      "source": [
        "For categorical data, you can plot a bar chart to see whether a particular category to view the count of the categories.\n",
        "\n",
        "Outliers in categorical data is tricky, because you have to determine whether it’s appropriate to call it an outlier based on context.\n",
        "\n",
        "Some outliers are more obvious. Let’s say there’s an experiment done where 1000 people choose between a glass of water and a glass of milk. If the final result is 1 person who chose a glass of water, and 999 people choosing a glass of milk, that 1 person can be considered an outlier.\n",
        "\n",
        "However, in some cases, outliers depend on context. In my example, you see that Manhattan and Brooklyn has significantly more data than Staten Island. This doesn’t count as an outlier, since Manhattan and Brooklyn has a higher housing density as compared to Staten Island."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "7SU6nEUR6H83",
        "outputId": "47574fc4-9dd8-4396-d4f7-e5951071196b"
      },
      "source": [
        "MiceImputed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MRNO</th>\n",
              "      <th>AGE</th>\n",
              "      <th>GENDER</th>\n",
              "      <th>DISTRICT</th>\n",
              "      <th>TEHSIL</th>\n",
              "      <th>REPORT_VERIFIED</th>\n",
              "      <th>CPT_ID</th>\n",
              "      <th>RESULT_VALUE</th>\n",
              "      <th>CPT_ID.1</th>\n",
              "      <th>RESULT_TEXT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10373.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21463.0</td>\n",
              "      <td>1.000000e+15</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000e+15</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10373.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21462.0</td>\n",
              "      <td>1.000000e+15</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000e+15</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10312.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10809.0</td>\n",
              "      <td>1.000000e+15</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000e+15</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10313.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12521.0</td>\n",
              "      <td>1.000000e+15</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000e+15</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10315.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2063.0</td>\n",
              "      <td>1.000000e+15</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000e+15</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12343</th>\n",
              "      <td>3001.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3669.0</td>\n",
              "      <td>1.000000e+15</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000e+15</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15056</th>\n",
              "      <td>2531.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19534.0</td>\n",
              "      <td>1.000000e+15</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000e+15</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13513</th>\n",
              "      <td>7286.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8439.0</td>\n",
              "      <td>1.000000e+15</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000e+15</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8974</th>\n",
              "      <td>744.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10606.0</td>\n",
              "      <td>1.000000e+15</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000e+15</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18480</th>\n",
              "      <td>4737.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12356.0</td>\n",
              "      <td>1.000000e+15</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000e+15</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>34554 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          MRNO   AGE  GENDER  ...  RESULT_VALUE      CPT_ID.1  RESULT_TEXT\n",
              "1      10373.0  41.0     1.0  ...           1.0  1.000000e+15          0.0\n",
              "2      10373.0  41.0     1.0  ...           1.0  1.000000e+15          0.0\n",
              "3      10312.0  23.0     1.0  ...           1.0  1.000000e+15          0.0\n",
              "4      10313.0  40.0     1.0  ...           1.0  1.000000e+15          0.0\n",
              "5      10315.0  26.0     0.0  ...           1.0  1.000000e+15          0.0\n",
              "...        ...   ...     ...  ...           ...           ...          ...\n",
              "12343   3001.0  65.0     0.0  ...           1.0  1.000000e+15          1.0\n",
              "15056   2531.0  29.0     0.0  ...           1.0  1.000000e+15          1.0\n",
              "13513   7286.0  84.0     1.0  ...           1.0  1.000000e+15          1.0\n",
              "8974     744.0   9.0     1.0  ...           1.0  1.000000e+15          1.0\n",
              "18480   4737.0  20.0     1.0  ...           1.0  1.000000e+15          1.0\n",
              "\n",
              "[34554 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "-hObhvoi6AUb",
        "outputId": "dd29e3de-e5eb-4627-8259-307a3ad219b4"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "MiceImputed['DISTRICT'].value_counts().plot.bar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f573a46b350>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fOVRcZP6aTT"
      },
      "source": [
        "**Dealing with outliers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZfdOd6I6ccB"
      },
      "source": [
        "Dealing with outliers is similar to removing missing values, the only difference is the way you find outliers.\n",
        "\n",
        "To categorize numerical values as outliers, there are statistical techniques like using the standard deviation and the Interquartile range. You can refer to this article for code examples to do that.\n",
        "\n",
        "For categorical values, if they have very low frequency (like Staten island in the example above), it still may become a problem for your model. Depending on context and nature of the data, you can choose to group them into one category, for example “Others”. This way your model will be less biased and you’re not losing any information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAFiOSxhxeYd"
      },
      "source": [
        "# **10- Data spliting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf0zg0EIxjvt"
      },
      "source": [
        "X=MiceImputed.drop('RESULT_TEXT',axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlZjN0iUxwvk"
      },
      "source": [
        "y=MiceImputed[['RESULT_TEXT']]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-eJxgVEx57E"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_ZFJl91-Y-J"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(df[['sex','embarked','alone','pclass']],\n",
        "                                              df['survived'],test_size=0.3,random_state=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOu2ttBhIqPr"
      },
      "source": [
        "# **References**\n",
        "\n",
        "[1-Fill Missing Values in a Dataset using Python](https://thecleverprogrammer.com/2021/05/29/fill-missing-values-in-a-dataset-using-python/)\n",
        "\n",
        "[2- Data Cleaning with Python](https://medium.com/bitgrit-data-science-publication/data-cleaning-with-python-f6bc3da64e45)\n",
        "\n",
        "[3- SMOTE using Python](https://towardsdatascience.com/applying-smote-for-class-imbalance-with-just-a-few-lines-of-code-python-cdf603e58688)\n",
        "\n",
        "[4-Protecting your Money: Detecting Credit Card Fraud with ML/DL](https://towardsdatascience.com/protecting-your-money-detecting-credit-card-fraud-with-ml-dl-2c4a9b9a0779)\n",
        "\n",
        "[5-How to Make Your Machine Learning Models Robust to Outliers](https://heartbeat.comet.ml/how-to-make-your-machine-learning-models-robust-to-outliers-44d404067d07)\n",
        "\n",
        "[6-What Is Encoding? And Its Importance in Data Science!](https://medium.datadriveninvestor.com/what-is-encoding-and-its-importance-in-data-science-6a2b0cce8e8e)\n",
        "\n",
        "[7-Nominal And Ordinal Encoding In Data Science!](https://medium.com/nerd-for-tech/nominal-and-ordinal-encoding-in-data-science-c93872601f16)\n",
        "\n",
        "[Feature Engineering for Categorical Data](https://medium.com/geekculture/feature-engineering-for-categorical-data-a77a04b3308)\n",
        "\n",
        "[Handling Imbalanced Datasets With Oversampling Techniques. It’s Pros & Cons.](https://medium.com/analytics-vidhya/handling-imbalanced-datasets-with-oversampling-techniques-its-pros-cons-ba9f36ac5b71)\n",
        "\n",
        "[8-Overcoming Imbalanced Dataset](https://xzz201920.medium.com/imbalanced-dataset-26732a333cf7)\n",
        "\n",
        "[9-How to handle Categorical variables?](https://medium.com/geekculture/how-to-handle-categorical-variables-7c1ee198c55c)\n",
        "\n",
        "[Python Tricks for Data Science\n",
        "](https://medium.com/analytics-vidhya/python-tricks-for-data-science-fd038ab838a)\n",
        "\n",
        "[7 Pandas Functions Every Data Scientist Should Know](https://medium.com/trymito/7-pandas-functions-every-data-scientist-should-know-d209b1116a16)\n",
        "\n",
        "[10 Fantastic Python Packages](https://levelup.gitconnected.com/10-fantastic-python-packages-af2a16a1183a)\n",
        "\n",
        "[Five Cool Python Libraries for Data Science](https://pub.towardsai.net/five-cool-python-libraries-for-data-science-7f1fce402b90)"
      ]
    }
  ]
}