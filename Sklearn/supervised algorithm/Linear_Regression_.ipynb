{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "neural-networks-deep-learning",
      "graded_item_id": "XaIWT",
      "launcher_item_id": "zAgPl"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "Linear Regression .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WZFQQORCAcS",
        "colab_type": "text"
      },
      "source": [
        "# Linear Regression \n",
        "\n",
        "**Introduction:**\n",
        "\n",
        "Regression is a process where we try to predict a continuous target variable based on independent variables. Scikit-Learn offers various regression models for performing regression learning.\n",
        "Let’s use below scikit-learn's various regression models for our purpose.\n",
        "\n",
        "Scikit-Learn also provides few datasets in-built with a package that we can load directly into memory and use for our purpose. We'll be using one such dataset called the Boston Housing dataset for our purpose. We'll be predicting the house price of a dataset based on other attributes from the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beVu-1UqCAcU",
        "colab_type": "text"
      },
      "source": [
        "## 1 - Importing necessary libraries ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF03EKpuCAcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import warnings\n",
        "import sys\n",
        "print(\"Python Version : \",sys.version)\n",
        "print(\"Scikit-Learn Version : \",sklearn.__version__)\n",
        "warnings.filterwarnings(\"ignore\") ## We'll silent future warnings using this command.\n",
        "np.set_printoptions(precision=3)\n",
        "\n",
        "## Beow magic function fits plot inside of current notebook. \n",
        "## There is another option to it (%matplotlib notebook) which opens plot in new notebook.\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK3oHVE6AacP",
        "colab_type": "text"
      },
      "source": [
        "**Linear Regression**\n",
        "\n",
        "In the Linear Regression Model, we try to fit the line through data in a way that has a minimum distance from all points in the dataset. Once we have found out proper line which has a minimum distance from all points in data and further optimization is not possible then we use that line to do further prediction on unseen data in the future.\n",
        "It's also known as Ordinary Least Squares because optimization function tries to minimize the squared distance between the line and all points in Train/Test Set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "nhYP15aoCAcf",
        "colab_type": "text"
      },
      "source": [
        "## 2 - Load Datasets ##\n",
        "We'll load Boston housing data provided by scikit-learn. It returns Bunch object which is almost the same as the dictionary. We'll also print details about the datase\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1wsGi52CAch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_boston ## function for loading boston data.\n",
        "boston = load_boston()\n",
        "#print(type(boston)) ## It returns Bunch object which is similar to dictionary.\n",
        "#print(boston.DESCR) ## DESCR attribute describes dataset.\n",
        "print('Feature Names : ' + str(boston.feature_names))\n",
        "print('Dataset shape : ' + str(boston.data.shape))\n",
        "print('Target shape : ' + str(boston.target.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4QYI2IoHWpL",
        "colab_type": "text"
      },
      "source": [
        "## 3 - Splitting Data Into Train/Test Sets ##\n",
        "We'll split the dataset into two parts:\n",
        "- Training data which will be used for the training model.\n",
        "\n",
        "- Test data against which accuracy of the trained model will be checked.\n",
        "\n",
        "train_test_split function of model_selection module of sklearn will help us split data into two sets with 80% for training and 20% for test purposes. We are also using seed(random_state=123) with train_test_split so that we always get the same split and can reproduce results in the future as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9JGZRKCCAcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split # Function for splitting dataset into train/test set.\n",
        "X = boston.data\n",
        "Y = boston.target\n",
        "## We can specify either one of train_size and test_size. Sklearn find out other by itself. I included both for explanation purpose.\n",
        "## random_state is used to reproduce same data splits again. If we don't set random_state then it generates different splits everytime.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, test_size = 0.2, random_state = 123)\n",
        "print('Train & Test sizes : ',X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zio5iZsm5-f6",
        "colab_type": "text"
      },
      "source": [
        "## 4-Initializing Model ##\n",
        "We are initializing the LinearRegression model below which is the basic model used extensively for regression tasks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BaUQqe16TDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression ## Linear Regression Implementation\n",
        "linear_regressor = LinearRegression()\n",
        "linear_regressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehTTQE9YJF1Q",
        "colab_type": "text"
      },
      "source": [
        "##5- Fitting Default Model To Train Data##\n",
        "We can train a model by passing train data and train labels. It returns objects of trained classifier as well after training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TvqFi8-XCAcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear_regressor.fit(X_train,Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izbM6eEUKAV-",
        "colab_type": "text"
      },
      "source": [
        "## 7-Evaluating Trained Model On Test Data ##\n",
        "Almost all models in Scikit-Learn API provides predict() method which can be used to predict the target variables on Test Set passed to it.\n",
        "We are comparing below housing prices predicted by our model with actual house prices of test data and train data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt-vctO1Kb3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_pred = linear_regressor.predict(X_test)\n",
        "print('First Few Actual Housing Prices(Test Data) : ' + str(Y_test[:5]))\n",
        "print('First Few Predicted Housing Prices(Test Data) : ' + str(y_test_pred[:5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5y_0Gn08Gr03",
        "colab_type": "text"
      },
      "source": [
        "Scikit-Learn's LinearRegresson model has a score() method which returns coefficient of determination  R2  based on the dataset and target variables passed to it. It returns a value between [0-1] with 1 being best. If it returns negative value means that the model performed quite bad.\n",
        "\n",
        "Note: Do not confuse  R2  with MSE as both are quite different. One can calculate MSE by using mean_squared_error provided by the metrics module of sklearn.\n",
        "\n",
        "Formula of  R2: \n",
        "\n",
        "R2=(1−u/v) \n",
        "where\n",
        "\n",
        "u=MSE=((ytrue−ypred)2).sum() \n",
        "v=((ytrue−ytrue.mean())2).sum()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4Za5NOgG_Cm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('R^2 Score on Test Data : %.3f'%linear_regressor.score(X_train, Y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XZ1CeiCHH3i",
        "colab_type": "text"
      },
      "source": [
        "As we discussed above, linear regression tries to generate lines through data in a way that mean squared error between actual labels and target is least. It is also the reason why its referred to as Ordinary Least Squares by many ML Practitioners as it tries to minimize squared differences between predicted and actual labels. We can access coordinates of that line through coef_ and intercept_ attributes of regressor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXHn1mLCHONk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Weight Coefficients : '+ str(linear_regressor.coef_))\n",
        "print('\\nY-Axis Intercept : '+ str(linear_regressor.intercept_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x8QNZN3CAdF",
        "colab_type": "text"
      },
      "source": [
        "## 8 -Visualizing Prediction Results On Test Data ##\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNBdXxiHLfLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sorted_labels_acc_to_test_y = list(sorted(zip(Y_test, y_test_pred), key=lambda x: x[1]))\n",
        "sorted_test_y, sorted_test_preds = zip(*sorted_labels_acc_to_test_y)\n",
        "\n",
        "with plt.style.context(('ggplot', 'seaborn')):\n",
        "    plt.scatter(range(len(sorted_test_y)),sorted_test_y, s=75, alpha=0.7, label='Actual')\n",
        "    plt.scatter(range(len(sorted_test_preds)), sorted_test_preds, s=75, alpha=0.7, label='Prediction')\n",
        "    plt.ylabel('House Price')\n",
        "    plt.title('Actual vs Predicted House Prices of Test Data')\n",
        "    plt.legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdpTOYOlCAdP",
        "colab_type": "text"
      },
      "source": [
        "## 9- Ridge Regression(L2 Penalty)\n",
        "\n",
        "\n",
        "Ridge regression is another estimator where we introduce regularization(L2 regularization) in the cost minimization function. The introduction of this regularization pushes all weights near zero but not making them exactly zero. It makes all the weight quite small."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTe0Qqi3CAeA",
        "colab_type": "text"
      },
      "source": [
        "## 10 - Initializing Model ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq4Ho1l8Ksjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import Ridge ## Linear Regression Implementation\n",
        "ridge_regressor = Ridge()\n",
        "ridge_regressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXa4ttgczPfN",
        "colab_type": "text"
      },
      "source": [
        "Below we are trying saga solver for our purpose. We can only use penalties l2, l1, elasticnet or no penalty(none) with this algorithm. It's the only algorithm which supports elasticnet penalty. It works faster for large datasets.# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNgIRP9ezR5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "params = {'penalty' : ['l1', 'l2','elasticnet', 'none'],\n",
        "         'fit_intercept': [True, False],\n",
        "         'C': np.linspace(0.1,1.0,10),\n",
        "         'l1_ratio': np.linspace(0.1,1.0,10)}\n",
        "\n",
        "grid = GridSearchCV(LogisticRegression(random_state=1, solver='saga', n_jobs=-1), param_grid=params, cv=3, n_jobs=-1)\n",
        "grid.fit(X_train, Y_train)\n",
        "\n",
        "print('Train Accuracy : %.3f'%grid.best_estimator_.score(X_train, Y_train))\n",
        "print('Test Accuracy : %.3f'%grid.best_estimator_.score(X_test, Y_test))\n",
        "print('Best Score Through Grid Search : %.3f'%grid.best_score_)\n",
        "print('Best Parameters : ',grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrZx-6XeziR0",
        "colab_type": "text"
      },
      "source": [
        "**Printing First Few Cross Validation Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q87nKz4zxr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_val_results = pd.DataFrame(grid.cv_results_)\n",
        "print('Number of Various Combinations of Parameters Tried : %d'%len(cross_val_results))\n",
        "cross_val_results.head() ## Printing first few results."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEmkNdqh0IF7",
        "colab_type": "text"
      },
      "source": [
        "Below we are trying sag solver for our purpose. We can only use penalty l2 or no penalty(none) with this algorithm. It works faster for large datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pmvm9kmy0MUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "params = {'penalty' : ['l2', 'none'],\n",
        "         'fit_intercept': [True, False],\n",
        "         'C': np.linspace(0.1,1.0,10),\n",
        "         'l1_ratio': np.linspace(0.1,1.0,10)}\n",
        "\n",
        "grid = GridSearchCV(LogisticRegression(random_state=1, solver='sag', n_jobs=-1), param_grid=params, cv=3, n_jobs=-1)\n",
        "grid.fit(X_train, Y_train)\n",
        "\n",
        "print('Train Accuracy : %.3f'%grid.best_estimator_.score(X_train, Y_train))\n",
        "print('Test Accuracy : %.3f'%grid.best_estimator_.score(X_test, Y_test))\n",
        "print('Best Score Through Grid Search : %.3f'%grid.best_score_)\n",
        "print('Best Parameters : ',grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Sq0XpVN0UZ7",
        "colab_type": "text"
      },
      "source": [
        "**Printing First Few Cross Validation Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ2nyHRV0dnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_val_results = pd.DataFrame(grid.cv_results_)\n",
        "print('Number of Various Combinations of Parameters Tried : %d'%len(cross_val_results))\n",
        "cross_val_results.head() ## Printing first few results."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuzUSRhS00EA",
        "colab_type": "text"
      },
      "source": [
        "Below we are trying lbfgs solver for our purpose. We can only use penalty l2 or no penalty(none) with this algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdMC_1w607mF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "params = {'penalty' : ['l2','none'],\n",
        "         'fit_intercept': [True, False],\n",
        "         'C': np.linspace(0.1,1.0,10),\n",
        "         'l1_ratio': np.linspace(0.1,1.0,10)}\n",
        "\n",
        "grid = GridSearchCV(LogisticRegression(random_state=1, solver='lbfgs', n_jobs=-1), param_grid=params, cv=3, n_jobs=-1)\n",
        "grid.fit(X_train, Y_train)\n",
        "\n",
        "print('Train Accuracy : %.3f'%grid.best_estimator_.score(X_train, Y_train))\n",
        "print('Test Accuracy : %.3f'%grid.best_estimator_.score(X_test, Y_test))\n",
        "print('Best Score Through Grid Search : %.3f'%grid.best_score_)\n",
        "print('Best Parameters : ',grid.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUnd-y071Epv",
        "colab_type": "text"
      },
      "source": [
        "**Printing First Few Cross Validation Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsBaFnzd1U_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_val_results = pd.DataFrame(grid.cv_results_)\n",
        "print('Number of Various Combinations of Parameters Tried : %d'%len(cross_val_results))\n",
        "\n",
        "cross_val_results.head() ## Printing first few results."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcZ4fX2j1fcs",
        "colab_type": "text"
      },
      "source": [
        "Below we are trying newton-cg solver for our purpose. We can only use penalty l2 or no penalty(none) with this algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf-y4XBE1jTC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "7734bad0-4ceb-4fb3-8c51-9b12166a8654"
      },
      "source": [
        "%%time\n",
        "\n",
        "params = {'penalty' : ['l2','none'],\n",
        "         'fit_intercept': [True, False],\n",
        "         'C': np.linspace(0.1,1.0,10),\n",
        "         'l1_ratio': np.linspace(0.1,1.0,10)}\n",
        "\n",
        "grid = GridSearchCV(LogisticRegression(random_state=1, solver='newton-cg', n_jobs=-1), param_grid=params, cv=3, n_jobs=-1)\n",
        "grid.fit(X_train, Y_train)\n",
        "\n",
        "print('Train Accuracy : %.3f'%grid.best_estimator_.score(X_train, Y_train))\n",
        "print('Test Accuracy : %.3f'%grid.best_estimator_.score(X_test, Y_test))\n",
        "print('Best Score Through Grid Search : %.3f'%grid.best_score_)\n",
        "print('Best Parameters : ',grid.best_params_)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy : 0.975\n",
            "Test Accuracy : 0.967\n",
            "Best Score Through Grid Search : 0.975\n",
            "Best Parameters :  {'C': 0.4, 'fit_intercept': False, 'l1_ratio': 0.1, 'penalty': 'l2'}\n",
            "CPU times: user 2.01 s, sys: 80.2 ms, total: 2.09 s\n",
            "Wall time: 1min 2s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1501: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
            "  \"(penalty={})\".format(self.penalty))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0jjIpLL1rqe",
        "colab_type": "text"
      },
      "source": [
        "**Printing First Few Cross Validation Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nbzyTxc12R7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_val_results = pd.DataFrame(grid.cv_results_)\n",
        "print('Number of Various Combinations of Parameters Tried : %d'%len(cross_val_results))\n",
        "cross_val_results.head() ## Printing first few results."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05Gq2A7BCAeX",
        "colab_type": "text"
      },
      "source": [
        "## 11 - K-Nearest Neighbors##\n",
        "\n",
        " K-nearest neighbor is one of the simplest algorithms which maintains all points from the train dataset and class to which it belongs. Later on, whenever a new unknown point comes for prediction it checks a predefined number of points nearer to that new point and based on majority class it assigns that majority class to a new point.n_neighbors is used to set the number of neighbors to check for predicting class for new unseen points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWCpBVwViJPO",
        "colab_type": "text"
      },
      "source": [
        "### 11.1 Initializing Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKE53swWipAU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
        "knn_classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6as5LRNgjTng",
        "colab_type": "text"
      },
      "source": [
        "### 11.2 Fitting Model To Train Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld1_nNE_mDcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "knn_classifier.fit(X_train,Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "yN3QOkmDCAed",
        "colab_type": "text"
      },
      "source": [
        "### 11.3 - Evaluating Trained Model On Test Data.###\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKMoGy7D4KXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_preds = knn_classifier.predict(X_test)\n",
        "print(Y_preds)\n",
        "print(Y_test)\n",
        "print('Accuracy : %.3f'%(Y_preds == Y_test).mean())\n",
        "print('Accuracy : %.3f'%knn_classifier.score(X_test, Y_test)) ## Score method also evaluates accuracy for classification models."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhsVrbTu4SqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(knn_classifier.predict_proba(X_test)[:10]) ## It returns probability predicted by model for each class for each example."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO6HAiq04ZKr",
        "colab_type": "text"
      },
      "source": [
        "### 11.4 Visualizing Prediction Results On Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woRGjqgH4lTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with plt.style.context(('ggplot','seaborn')):\n",
        "    plt.figure(figsize=(12,5))\n",
        "    plt.subplot(121)\n",
        "    for i,c in [(0,'red'),(1,'green'),(2,'blue')]:\n",
        "        plt.scatter(X_test[Y_test==i,0],X_test[Y_test==i,3], c=c, s=40, marker='s', label=iris.target_names[i])\n",
        "    plt.xlabel(iris.feature_names[0])\n",
        "    plt.ylabel(iris.feature_names[3])\n",
        "    plt.legend(loc='best')\n",
        "    plt.title('Actual')\n",
        "\n",
        "    plt.subplot(122)\n",
        "    for i,c in [(0,'red'),(1,'green'),(2,'blue')]:\n",
        "        plt.scatter(X_test[Y_preds==i,0],X_test[Y_preds==i,3], c=c, s=40, marker='s', label=iris.target_names[i])\n",
        "    plt.xlabel(iris.feature_names[0])\n",
        "    plt.ylabel(iris.feature_names[3])\n",
        "    plt.legend(loc='best')\n",
        "    plt.title('Prediction');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xH8Qq6J72il",
        "colab_type": "text"
      },
      "source": [
        "###11.5 -Finetuning Model By Doing Grid Search On Various Hyperparameters.#\n",
        "Below are list of hypterparameters that we can tune to get best estimator for our data.\n",
        "\n",
        "**n_neighbors** - Number of neighbors to use to determine class of target. default=5\n",
        "\n",
        "**algorithm** - Algorithm for finding nearest neighbors. It takes one of the values from list [ball_tree, kd_tree, brute, auto]. default=auto\n",
        "\n",
        "**leaf_size** - Leaf size of KDTree and BallTree. It controls speed of construction and quer of tree as well as memory requirement of tree.default=30"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn6-jer48jeF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "11c6b221-adbf-4943-f20b-3f8ed76cdeb8"
      },
      "source": [
        "%%time\n",
        "\n",
        "params = {'n_neighbors' : np.arange(1,10),\n",
        "         'leaf_size': np.arange(5,50,5),\n",
        "         'algorithm': ['ball_tree', 'kd_tree', 'brute', 'auto']}\n",
        "\n",
        "grid = GridSearchCV(KNeighborsClassifier(n_jobs=-1), param_grid=params, cv=3, n_jobs=-1)\n",
        "grid.fit(X_train, Y_train)\n",
        "\n",
        "print('Train Accuracy : %.3f'%grid.best_estimator_.score(X_train, Y_train))\n",
        "print('Test Accuracy : %.3f'%grid.best_estimator_.score(X_test, Y_test))\n",
        "print('Best Score Through Grid Search : %.3f'%grid.best_score_)\n",
        "print('Best Parameters : ',grid.best_params_)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy : 0.983\n",
            "Test Accuracy : 0.933\n",
            "Best Score Through Grid Search : 0.983\n",
            "Best Parameters :  {'algorithm': 'ball_tree', 'leaf_size': 5, 'n_neighbors': 3}\n",
            "CPU times: user 2.38 s, sys: 164 ms, total: 2.55 s\n",
            "Wall time: 53.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J75Rv0fr8qWA",
        "colab_type": "text"
      },
      "source": [
        "### 11.6 Printing First Few Cross Validation Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDoYPVl48x_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_val_results = pd.DataFrame(grid.cv_results_)\n",
        "print('Number of Various Combinations of Parameters Tried : %d'%len(cross_val_results))\n",
        "cross_val_results.head() ## Printing first few results."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm7uTbEWCAei",
        "colab_type": "text"
      },
      "source": [
        "References:\n",
        "Supervised Learning - Regression¶\n",
        "\n",
        "https://coderzcolumn.com/tutorials/machine-learning/supervised-learning-regression-using-scikit-learn-sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LvqfD4BCAei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}